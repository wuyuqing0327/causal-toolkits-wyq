{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq AugLiChem"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEBTUXW4u8Uy",
    "outputId": "8b09387c-d355-474c-ae10-130ba512dc01"
   },
   "id": "PEBTUXW4u8Uy",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq torch_geometric"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fklz1j1vvldf",
    "outputId": "3872b911-8ead-4310-c5c3-d39f9fe9f3be"
   },
   "id": "Fklz1j1vvldf",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, BatchNorm, JumpingKnowledge\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from auglichem.molecule import Compose, RandomAtomMask, RandomBondDelete, MotifRemoval\n",
    "from auglichem.molecule.data import MoleculeDatasetWrapper"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T17:01:40.715245Z",
     "start_time": "2024-05-07T17:01:40.712506Z"
    },
    "id": "6b58946add4d2f07"
   },
   "id": "6b58946add4d2f07",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"sample_data/new_data.json\", \"r\") as f:\n",
    "    cleaned_data = json.load(f)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T17:01:42.881272Z",
     "start_time": "2024-05-07T17:01:41.083001Z"
    },
    "id": "ea80f9bd462fb5d9"
   },
   "id": "ea80f9bd462fb5d9",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def count_unique_attributes(data):\n",
    "    # Sets to store unique values of node attributes\n",
    "    atomic_set = set()\n",
    "    formal_charge_set = set()\n",
    "    valence_set = set()\n",
    "    hybridization_set = set()\n",
    "    radical_electrons_set = set()\n",
    "\n",
    "    # Sets to store unique values of edge attributes\n",
    "    type_set = set()\n",
    "    stereo_set = set()\n",
    "\n",
    "    # Loop through data structure to collect unique values\n",
    "    for smiles, features in data.items():\n",
    "        # Collect node attributes\n",
    "        for node in features['node_id_feature'].values():\n",
    "            atomic_set.add(node['atomic'])\n",
    "            formal_charge_set.add(node['formal_charge'])\n",
    "            valence_set.add(node['valence'])\n",
    "            hybridization_set.add(node['hybridization'])\n",
    "            radical_electrons_set.add(node['radical_electrons'])\n",
    "\n",
    "        # Collect edge attributes\n",
    "        for edge in features['edge_features']:\n",
    "            type_set.add(edge['type'])\n",
    "            stereo_set.add(edge['stereo'])\n",
    "\n",
    "    # Create a result dictionary for easy display\n",
    "    result = {\n",
    "        \"unique_num_atomic\": len(atomic_set),\n",
    "        \"unique_num_formal_charge\": len(formal_charge_set),\n",
    "        \"unique_num_valence\": len(valence_set),\n",
    "        \"unique_num_hybridization\": len(hybridization_set),\n",
    "        \"unique_num_radical_electrons\": len(radical_electrons_set),\n",
    "        \"unique_num_type\": len(type_set),\n",
    "        \"unique_num_stereo\": len(stereo_set)\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Calculate the number of unique values for each property\n",
    "unique_properties = count_unique_attributes(cleaned_data)\n",
    "print(unique_properties)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:19:16.119451Z",
     "start_time": "2024-05-07T15:19:16.075319Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93f9cc5bc7439509",
    "outputId": "2e089dd4-22b0-40cf-962f-4af6d10b51f1"
   },
   "id": "93f9cc5bc7439509",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Dataset class\n",
    "class MolecularGraphDataset(Dataset):\n",
    "    def __init__(self, cleaned_data, transform=None, pre_transform=None):\n",
    "        super(MolecularGraphDataset, self).__init__(transform=transform, pre_transform=pre_transform)\n",
    "        self.graphs = list(cleaned_data.values())\n",
    "        self._indices = range(len(self.graphs))\n",
    "        self.targets = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._indices)\n",
    "\n",
    "    def get(self, idx):\n",
    "        graph_info = self.graphs[idx]\n",
    "        return self.create_pyg_data(graph_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.get(self._indices[idx])\n",
    "        data = data if self.transform is None else self.transform(data)\n",
    "        return data\n",
    "\n",
    "    def extract_targets(self):\n",
    "        for graph_info in self.graphs:\n",
    "            for node_id, node_info in graph_info[\"target_variable\"].items():\n",
    "                self.targets.append([\n",
    "                    node_info[\"mass\"],\n",
    "                    node_info[\"charge\"],\n",
    "                    node_info[\"sigma\"],\n",
    "                    node_info[\"epsilon\"]\n",
    "                ])\n",
    "        return self.targets\n",
    "\n",
    "    def create_pyg_data(self, graph_info):\n",
    "        # Extract nodes and edges from the graph information\n",
    "        node_id_feature = graph_info[\"node_id_feature\"]\n",
    "        edge_features = graph_info[\"edge_features\"]\n",
    "        target_variable = graph_info[\"target_variable\"]\n",
    "\n",
    "        # Create the node feature matrix\n",
    "        node_ids = sorted(node_id_feature.keys())\n",
    "        node_features = []\n",
    "        for node_id in node_ids:\n",
    "            features = [\n",
    "                node_id_feature[node_id][\"atomic\"],\n",
    "                node_id_feature[node_id][\"valence\"],\n",
    "                node_id_feature[node_id][\"formal_charge\"],\n",
    "                node_id_feature[node_id][\"aromatic\"],\n",
    "                node_id_feature[node_id][\"hybridization\"],\n",
    "                node_id_feature[node_id][\"radical_electrons\"]\n",
    "            ]\n",
    "            node_features.append(features)\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "        # Create the edge list\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for edge in edge_features:\n",
    "            edge_index.append([edge[\"source\"], edge[\"target\"]])\n",
    "            edge_attr.append([\n",
    "                edge[\"type\"],\n",
    "                edge[\"stereo\"],\n",
    "                edge[\"aromatic\"],\n",
    "                edge[\"conjugated\"]\n",
    "            ])\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "        # Create the target variable tensor\n",
    "        target_list = [target_variable[node_id] for node_id in node_ids]\n",
    "        y = torch.tensor([[t[\"mass\"], t[\"charge\"], t[\"sigma\"], t[\"epsilon\"]] for t in target_list], dtype=torch.float)\n",
    "\n",
    "        #mean = torch.mean(y, dim=0)\n",
    "        #std = torch.std(y, dim=0)\n",
    "\n",
    "        # Standardize the target variables\n",
    "        #y = (y - mean) / std\n",
    "\n",
    "        # Return the graph as a Data object\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:58:25.047885Z",
     "start_time": "2024-05-07T12:58:25.042808Z"
    },
    "id": "ff1ef6cc61d6b719"
   },
   "id": "ff1ef6cc61d6b719",
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = MolecularGraphDataset(cleaned_data)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:58:26.251846Z",
     "start_time": "2024-05-07T12:58:26.248418Z"
    },
    "id": "846d51633e0cc2e4"
   },
   "id": "846d51633e0cc2e4",
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "def apply_random_mask(mol_graph, p, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    N = mol_graph.x.size(0)\n",
    "    num_mask_nodes = max(1, math.floor(p * N))\n",
    "    mask_nodes = random.sample(list(range(N)), num_mask_nodes)\n",
    "\n",
    "    aug_mol_graph = deepcopy(mol_graph)\n",
    "    for atom_idx in mask_nodes:\n",
    "        aug_mol_graph.x[atom_idx, :] = torch.zeros(6)\n",
    "\n",
    "    return aug_mol_graph\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    apply_random_mask(dataset[i], 0.1)"
   ],
   "metadata": {
    "id": "0RXUc7O537PJ"
   },
   "id": "0RXUc7O537PJ",
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NodeEmbedding(nn.Module):\n",
    "    def __init__(self, num_atomic, num_valence, num_formal_charge, num_hybridization, num_radical_electrons, embedding_dim):\n",
    "        super(NodeEmbedding, self).__init__()\n",
    "        self.atomic_embedding = nn.Embedding(num_atomic, embedding_dim)\n",
    "        self.valence_embedding = nn.Embedding(num_valence, embedding_dim)\n",
    "        self.formal_charge_embedding = nn.Embedding(num_formal_charge, embedding_dim)\n",
    "        self.hybridization_embedding = nn.Embedding(num_hybridization, embedding_dim)\n",
    "        self.radical_electrons_embedding = nn.Embedding(num_radical_electrons, embedding_dim)\n",
    "\n",
    "    def forward(self, atomic, valence, formal_charge, aromatic, hybridization, radical_electrons):\n",
    "        atomic_embed = self.atomic_embedding(atomic)\n",
    "        valence_embed = self.valence_embedding(valence)\n",
    "        formal_charge_embed = self.formal_charge_embedding(formal_charge)\n",
    "        hybridization_embed = self.hybridization_embedding(hybridization)\n",
    "        radical_electrons_embed = self.radical_electrons_embedding(radical_electrons)\n",
    "\n",
    "        # Concatenate boolean features\n",
    "        other_features = torch.stack([aromatic], dim=1).float()\n",
    "\n",
    "        # Concatenate all features together\n",
    "        return torch.cat([atomic_embed, valence_embed, formal_charge_embed, hybridization_embed, radical_electrons_embed, other_features], dim=1)\n",
    "\n",
    "class EdgeEmbedding(nn.Module):\n",
    "    def __init__(self, num_type, num_stereo, embedding_dim):\n",
    "        super(EdgeEmbedding, self).__init__()\n",
    "        self.type_embedding = nn.Embedding(num_type, embedding_dim)\n",
    "        self.stereo_embedding = nn.Embedding(num_stereo, embedding_dim)\n",
    "\n",
    "    def forward(self, type_, stereo, aromatic, conjugated):\n",
    "        type_embed = self.type_embedding(type_)\n",
    "        stereo_embed = self.stereo_embedding(stereo)\n",
    "\n",
    "        # Concatenate boolean features directly\n",
    "        other_features = torch.stack([aromatic, conjugated], dim=1).float()\n",
    "\n",
    "        # Concatenate all features together\n",
    "        return torch.cat([type_embed, stereo_embed, other_features], dim=1)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:24:04.127502Z",
     "start_time": "2024-05-07T15:24:04.123377Z"
    },
    "id": "3b7d0c1dec527eb7"
   },
   "id": "3b7d0c1dec527eb7",
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ImprovedGNNWithEmbeddings(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_embedding_dim, edge_embedding_dim, hidden_dim, output_dim, num_layers = 5, num_atomic = 12, num_valence = 7, num_hybridization = 5, num_type = 4, num_stereo = 3 ,num_formal_charge = 3, num_radical_electrons = 3):\n",
    "        super(ImprovedGNNWithEmbeddings, self).__init__()\n",
    "        self.node_embedding = NodeEmbedding(num_atomic, num_valence, num_formal_charge, num_hybridization, num_radical_electrons, node_embedding_dim)\n",
    "        self.edge_embedding = EdgeEmbedding(num_type, num_stereo, edge_embedding_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "\n",
    "        # Define the first GINEConv layer, with the correct edge_dim specified\n",
    "        self.convs.append(GINEConv(\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(node_input_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            ),\n",
    "            edge_dim=edge_input_dim\n",
    "        ))\n",
    "        self.norms.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        # Additional GINEConv layers, each with the correct edge_dim\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GINEConv(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "                ),\n",
    "                edge_dim=edge_input_dim\n",
    "            ))\n",
    "            self.norms.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        # Jumping Knowledge mechanism\n",
    "        self.jump = JumpingKnowledge(mode=\"cat\")\n",
    "\n",
    "        # Final fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim * num_layers, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        features = []\n",
    "\n",
    "        # Pass through GINEConv layers and apply batch normalization\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.relu(norm(x))\n",
    "            features.append(x)\n",
    "\n",
    "        # Apply Jumping Knowledge (JK) to concatenate all layers\n",
    "        x = self.jump(features)\n",
    "\n",
    "        # Directly pass through the linear layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T16:17:48.429727Z",
     "start_time": "2024-05-07T16:17:48.424463Z"
    },
    "id": "302b42750e77409d"
   },
   "id": "302b42750e77409d",
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "node_input_dim = 6  # node feature dimension\n",
    "edge_input_dim = 4  # edge feature dimension\n",
    "hidden_dim = 128\n",
    "output_dim = 4  # The number of outputs (mass, charge, sigma, epsilon)\n",
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# model = ImprovedGNNWithEdgeFeatures(node_input_dim, edge_input_dim, hidden_dim, output_dim)\n",
    "model = ImprovedGNNWithEmbeddings( node_embedding_dim = 32, edge_embedding_dim = 32, hidden_dim = 128, output_dim = 4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Move model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cfbb21124a7fd29",
    "outputId": "7f6844b0-08e2-4797-81ed-d55804626fd2"
   },
   "id": "4cfbb21124a7fd29",
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def unstandardize(targets, mean, std):\n",
    "    return targets * std + mean\n",
    "\n",
    "mean = torch.tensor(mean).to(device)\n",
    "std = torch.tensor(std).to(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goyNlLrxF_tL",
    "outputId": "2b95a8f6-97e6-41a8-87d3-f58bf41b9b5d"
   },
   "id": "goyNlLrxF_tL",
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Hyperparameters for early stopping\n",
    "patience = 30  # Stop if no improvement for 30 consecutive epochs\n",
    "min_delta = 0.00001  # Minimum improvement required to reset patience\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Split indices for train and validation sets\n",
    "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Subset datasets using the split indices\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# Create DataLoaders for the subsets\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation during validation\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)  # Move data to the correct device\n",
    "            out = model(data)  # Forward pass\n",
    "\n",
    "            #out_unscaled = unstandardize(out, mean, std)\n",
    "            #target_unscaled = unstandardize(data.y, mean, std)\n",
    "\n",
    "            loss = criterion(out, data.y)  # Compute validation loss\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "    return total_loss / len(val_loader.dataset)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)  # Move data to GPU or CPU\n",
    "        optimizer.zero_grad()  # Clear gradients from the last step\n",
    "        out = model(data)  # Forward pass\n",
    "        loss = criterion(out, data.y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Training loop with early stopping\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Check for improvement\n",
    "    if best_val_loss - val_loss > min_delta:\n",
    "        best_val_loss = val_loss  # New best validation loss\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "    else:\n",
    "        patience_counter += 1  # Increment patience counter\n",
    "\n",
    "    print(f\"Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check if patience counter has been exceeded\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered. Stopping training...\")\n",
    "\n",
    "        break"
   ],
   "metadata": {
    "id": "70663756a41b7f64",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa0f2d71-6829-475b-9e24-6159249fe895"
   },
   "id": "70663756a41b7f64",
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_with_indices_and_true_values(model, graph_data, device):\n",
    "    graph_data = graph_data.to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(graph_data)\n",
    "\n",
    "    node_indices = torch.arange(graph_data.num_nodes)\n",
    "    true_values = graph_data.y\n",
    "\n",
    "    # Combine predictions with indices and true values\n",
    "    indexed_predictions = list(zip(node_indices.cpu().numpy(), predictions.cpu().numpy(), true_values.cpu().numpy()))\n",
    "    return indexed_predictions\n",
    "\n",
    "# Example usage\n",
    "graph = val_dataset[1]  # Get a single graph\n",
    "graph_predictions_and_true_values = predict_with_indices_and_true_values(model, graph, device)\n",
    "\n",
    "# Display predictions and true values for each node\n",
    "print(\"Predictions and True Values for each node (index, prediction, true value):\")\n",
    "for index, prediction, true_value in graph_predictions_and_true_values:\n",
    "    print(f\"Node {index}: Prediction: {prediction}, True Value: {true_value}\")"
   ],
   "metadata": {
    "id": "8c903a1b0957e8f7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "416e06cb-4354-43db-dbaa-246b5b12d5b4"
   },
   "id": "8c903a1b0957e8f7",
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model and optimizer state\n",
    "torch.save(model.state_dict(), \"improved_gnn_model.pth\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T17:10:43.250041Z",
     "start_time": "2024-05-07T17:10:43.232409Z"
    },
    "id": "b56558e4c0e47cac"
   },
   "id": "b56558e4c0e47cac",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "31d752953c01b5ec"
   },
   "id": "31d752953c01b5ec",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

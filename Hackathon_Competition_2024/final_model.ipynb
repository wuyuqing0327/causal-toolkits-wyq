{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:53:06.559616Z",
     "start_time": "2024-05-08T06:53:06.555858Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, BatchNorm, JumpingKnowledge\n",
    "import torch.nn.functional as F\n",
    "import helper\n",
    "import data_preprocessing_training"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Dataset class\n",
    "class MolecularGraphTrain(Dataset):\n",
    "    def __init__(self, cleaned_data, transform=None, pre_transform=None):\n",
    "        super(MolecularGraphTrain, self).__init__(transform=transform, pre_transform=pre_transform)\n",
    "        self.graphs = list(cleaned_data.values())\n",
    "        self._indices = range(len(self.graphs))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._indices)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        graph_info = self.graphs[idx]\n",
    "        return self.create_pyg_data(graph_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.get(self._indices[idx])\n",
    "        data = data if self.transform is None else self.transform(data)\n",
    "        return data\n",
    "    \n",
    "    def create_pyg_data(self, graph_info):\n",
    "        # Extract nodes and edges from the graph information\n",
    "        node_id_feature = graph_info[\"node_id_feature\"]\n",
    "        edge_features = graph_info[\"edge_features\"]\n",
    "        target_variable = graph_info[\"target_variable\"]\n",
    "    \n",
    "        # Create the node feature matrix\n",
    "        node_ids = sorted(node_id_feature.keys())\n",
    "        node_features = []\n",
    "        for node_id in node_ids:\n",
    "            features = [\n",
    "                node_id_feature[node_id][\"atomic\"],\n",
    "                node_id_feature[node_id][\"valence\"],\n",
    "                node_id_feature[node_id][\"formal_charge\"],\n",
    "                node_id_feature[node_id][\"aromatic\"],\n",
    "                node_id_feature[node_id][\"hybridization\"],\n",
    "                node_id_feature[node_id][\"radical_electrons\"]\n",
    "            ]\n",
    "            node_features.append(features)\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "        # Create the edge list\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for edge in edge_features:\n",
    "            edge_index.append([edge[\"source\"], edge[\"target\"]])\n",
    "            edge_attr.append([\n",
    "                edge[\"type\"],\n",
    "                edge[\"stereo\"],\n",
    "                edge[\"aromatic\"],\n",
    "                edge[\"conjugated\"]\n",
    "            ])\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "        # Create the target variable tensor\n",
    "        target_list = [target_variable[node_id] for node_id in node_ids]\n",
    "        y = torch.tensor([[t[\"mass\"], t[\"charge\"], t[\"sigma\"], t[\"epsilon\"]] for t in target_list], dtype=torch.float)\n",
    "    \n",
    "        # Return the graph as a Data object\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:53:07.360975Z",
     "start_time": "2024-05-08T06:53:07.355638Z"
    }
   },
   "id": "99bba2df99121011",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Dataset class\n",
    "class MolecularGraphTest(Dataset):\n",
    "    def __init__(self, cleaned_data, transform=None, pre_transform=None):\n",
    "        super(MolecularGraphTest, self).__init__(transform=transform, pre_transform=pre_transform)\n",
    "        self.graphs = list(cleaned_data.values())\n",
    "        self._indices = range(len(self.graphs))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._indices)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        graph_info = self.graphs[idx]\n",
    "        return self.create_pyg_data(graph_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.get(self._indices[idx])\n",
    "        data = data if self.transform is None else self.transform(data)\n",
    "        return data\n",
    "    \n",
    "    def create_pyg_data(self, graph_info):\n",
    "        # Extract nodes and edges from the graph information\n",
    "        node_id_feature = graph_info[\"node_id_feature\"]\n",
    "        edge_features = graph_info[\"edge_features\"]\n",
    "    \n",
    "        # Create the node feature matrix\n",
    "        node_ids = sorted(node_id_feature.keys())\n",
    "        node_features = []\n",
    "        for node_id in node_ids:\n",
    "            features = [\n",
    "                node_id_feature[node_id][\"atomic\"],\n",
    "                node_id_feature[node_id][\"valence\"],\n",
    "                node_id_feature[node_id][\"formal_charge\"],\n",
    "                node_id_feature[node_id][\"aromatic\"],\n",
    "                node_id_feature[node_id][\"hybridization\"],\n",
    "                node_id_feature[node_id][\"radical_electrons\"]\n",
    "            ]\n",
    "            node_features.append(features)\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "        # Create the edge list\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for edge in edge_features:\n",
    "            edge_index.append([edge[\"source\"], edge[\"target\"]])\n",
    "            edge_attr.append([\n",
    "                edge[\"type\"],\n",
    "                edge[\"stereo\"],\n",
    "                edge[\"aromatic\"],\n",
    "                edge[\"conjugated\"]\n",
    "            ])\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "        # Return the graph as a Data object\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:56:45.409635Z",
     "start_time": "2024-05-08T06:56:45.403393Z"
    }
   },
   "id": "dc90f28c44b2703",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NodeEmbedding(nn.Module):\n",
    "    def __init__(self, num_atomic, num_valence, num_formal_charge, num_hybridization, num_radical_electrons, embedding_dim):\n",
    "        super(NodeEmbedding, self).__init__()\n",
    "        self.atomic_embedding = nn.Embedding(num_atomic, embedding_dim)\n",
    "        self.valence_embedding = nn.Embedding(num_valence, embedding_dim)\n",
    "        self.formal_charge_embedding = nn.Embedding(num_formal_charge, embedding_dim)\n",
    "        self.hybridization_embedding = nn.Embedding(num_hybridization, embedding_dim)\n",
    "        self.radical_electrons_embedding = nn.Embedding(num_radical_electrons, embedding_dim)\n",
    "\n",
    "    def forward(self, atomic, valence, formal_charge, aromatic, hybridization, radical_electrons):\n",
    "        atomic_embed = self.atomic_embedding(atomic)\n",
    "        valence_embed = self.valence_embedding(valence)\n",
    "        formal_charge_embed = self.formal_charge_embedding(formal_charge)\n",
    "        hybridization_embed = self.hybridization_embedding(hybridization)\n",
    "        radical_electrons_embed = self.radical_electrons_embedding(radical_electrons)\n",
    "\n",
    "        # Concatenate boolean features\n",
    "        other_features = torch.stack([aromatic], dim=1).float()\n",
    "\n",
    "        # Concatenate all features together\n",
    "        return torch.cat([atomic_embed, valence_embed, formal_charge_embed, hybridization_embed, radical_electrons_embed, other_features], dim=1)\n",
    "\n",
    "class EdgeEmbedding(nn.Module):\n",
    "    def __init__(self, num_type, num_stereo, embedding_dim):\n",
    "        super(EdgeEmbedding, self).__init__()\n",
    "        self.type_embedding = nn.Embedding(num_type, embedding_dim)\n",
    "        self.stereo_embedding = nn.Embedding(num_stereo, embedding_dim)\n",
    "\n",
    "    def forward(self, type_, stereo, aromatic, conjugated):\n",
    "        type_embed = self.type_embedding(type_)\n",
    "        stereo_embed = self.stereo_embedding(stereo)\n",
    "\n",
    "        # Concatenate boolean features directly\n",
    "        other_features = torch.stack([aromatic, conjugated], dim=1).float()\n",
    "\n",
    "        # Concatenate all features together\n",
    "        return torch.cat([type_embed, stereo_embed, other_features], dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:56:46.914246Z",
     "start_time": "2024-05-08T06:56:46.909354Z"
    }
   },
   "id": "be5c1beb5ca377f3",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ImprovedGNNWithEmbeddings(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_embedding_dim, edge_embedding_dim, hidden_dim, output_dim, num_layers = 6, num_atomic = 12, num_valence = 7, num_hybridization = 5, num_type = 4, num_stereo = 3 ,num_formal_charge = 3, num_radical_electrons = 1):\n",
    "        super(ImprovedGNNWithEmbeddings, self).__init__()\n",
    "        self.node_embedding = NodeEmbedding(num_atomic, num_valence, num_formal_charge, num_hybridization, num_radical_electrons, node_embedding_dim)\n",
    "        self.edge_embedding = EdgeEmbedding(num_type, num_stereo, edge_embedding_dim)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "\n",
    "        # Define the first GINEConv layer, with the correct edge_dim specified\n",
    "        self.convs.append(GINEConv(\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(node_input_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            ),\n",
    "            edge_dim=edge_input_dim, train_eps = True\n",
    "        ))\n",
    "        self.norms.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        # Additional GINEConv layers, each with the correct edge_dim\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GINEConv(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "                ),\n",
    "                edge_dim=edge_input_dim, train_eps = True\n",
    "            ))\n",
    "            self.norms.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        # Jumping Knowledge mechanism\n",
    "        self.jump = JumpingKnowledge(mode=\"cat\")\n",
    "\n",
    "        # Final fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim * num_layers, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        features = []\n",
    "\n",
    "        # Pass through GINEConv layers and apply batch normalization\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.relu(norm(x))\n",
    "            features.append(x)\n",
    "\n",
    "        # Apply Jumping Knowledge (JK) to concatenate all layers\n",
    "        x = self.jump(features)\n",
    "\n",
    "        # Directly pass through the linear layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:56:47.518162Z",
     "start_time": "2024-05-08T06:56:47.513064Z"
    }
   },
   "id": "e914ac2e07356efc",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import data_preprocessing_testing\n",
    "\n",
    "train_data = helper.load_data_from_file(\"data.json\")\n",
    "cleaned_data_train = data_preprocessing_training.extract_clean_data(train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:56:49.706499Z",
     "start_time": "2024-05-08T06:56:48.106681Z"
    }
   },
   "id": "a21590047cf6cde4",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "node_input_dim = 6  # node feature dimension\n",
    "edge_input_dim = 4  # edge feature dimension\n",
    "hidden_dim = 256\n",
    "output_dim = 4  # The number of outputs (mass, charge, sigma, epsilon)\n",
    "num_epochs = 500\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = ImprovedGNNWithEmbeddings(node_embedding_dim = 32, edge_embedding_dim = 32, hidden_dim = hidden_dim, output_dim = 4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Move model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T07:03:29.806007Z",
     "start_time": "2024-05-08T07:03:29.787276Z"
    }
   },
   "id": "f214a9335bdd46c3",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "# Set up the training and testing DataLoaders using PyTorch Geometric DataLoader\n",
    "train_dataset = MolecularGraphTrain(cleaned_data_train)\n",
    "\n",
    "\n",
    "# Use a smaller batch size for better memory management, particularly with graph data\n",
    "train_loader = PyGDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # Move data to the device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Model evaluation on the test dataset\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Convert predictions to a suitable format if needed\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T07:05:49.479945Z",
     "start_time": "2024-05-08T07:03:30.754568Z"
    }
   },
   "id": "32da7bc662878bf7",
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"improved_gnn_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T07:06:54.094780Z",
     "start_time": "2024-05-08T07:06:54.029025Z"
    }
   },
   "id": "8db5402e4ebd4802",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = helper.load_data_from_file(\"permutation_masked.json\")\n",
    "cleaned_data_test = data_preprocessing_testing.extract_clean_data(test_data)\n",
    "test_dataset = MolecularGraphTest(cleaned_data_test)\n",
    "test_loader = PyGDataLoader(test_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:27:23.697356Z",
     "start_time": "2024-05-08T08:27:23.654920Z"
    }
   },
   "id": "f3efe8347cb6180e",
   "execution_count": 117,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move data to the device\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Forward pass (prediction)\n",
    "        output = model(batch)\n",
    "\n",
    "        # Append the predictions\n",
    "        predictions.append(output.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:27:24.376411Z",
     "start_time": "2024-05-08T08:27:24.212162Z"
    }
   },
   "id": "1abcf5bbc287eb10",
   "execution_count": 118,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:27:24.627322Z",
     "start_time": "2024-05-08T08:27:24.622577Z"
    }
   },
   "id": "db1ac6439ee078b8",
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8afa7adb1688d74e",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
